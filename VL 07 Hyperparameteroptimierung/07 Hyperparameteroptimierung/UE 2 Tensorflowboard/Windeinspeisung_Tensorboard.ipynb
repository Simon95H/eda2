{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90386565",
   "metadata": {},
   "source": [
    "# Modellierung Windeinspeisung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28e0dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Lernziele**\n",
    "- Hyperparameteroptimierung mit tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab6c37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pakete und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe0d5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1903405886.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 49\u001b[1;36m\u001b[0m\n\u001b[1;33m    from KNN import KNN\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Datenorganisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "\n",
    "# Ploterstellung\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "# Datenvorbereitung\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Standardeinstellungen\n",
    "plt.rcParams['axes.xmargin'] = 0\n",
    "pd.set_option('display.precision',3)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Input, LSTM, Dense, Bidirectional, Dropout)\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint)\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import tensorboard\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "tensorboard.__version__\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "#sonst  Module \n",
    "import copy\n",
    "import sys\n",
    "from math import ceil\n",
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "# Eingene Module \n",
    "# temporäre Einbinden des neuen Pfades mit zu ladenden Dateien\n",
    "path = Path(sys.path[0])\n",
    "sys.path.append(os.path.join(os.path.dirname(path.parent.parent.parent.absolute(),'00_internalfunctions'))\n",
    "from KNN import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "580fe3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ../daten/windeinspeisung_bereinigt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Laden des vorbereiteten WinddatenFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m wind\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_hdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../daten/windeinspeisung_bereinigt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mObj1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\io\\pytables.py:414\u001b[0m, in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m     exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_buf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    416\u001b[0m store \u001b[38;5;241m=\u001b[39m HDFStore(path_or_buf, mode\u001b[38;5;241m=\u001b[39mmode, errors\u001b[38;5;241m=\u001b[39merrors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# can't auto open/close if we are using an iterator\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# so delegate to the iterator\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File ../daten/windeinspeisung_bereinigt does not exist"
     ]
    }
   ],
   "source": [
    "# Laden des vorbereiteten WinddatenFrame\n",
    "wind=pd.read_hdf('../daten/windeinspeisung_bereinigt','Obj1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ab04b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datenorganisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decab832",
   "metadata": {},
   "source": [
    "Erstellung eines KNN-Objektes mit normierten/Standardisierten Trainings/Validierungs- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493a478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vorgaben zur Datentrennung\n",
    "sections=(.6,.25,.15)\n",
    "shuffle=False\n",
    "\n",
    "# Vorbereitete Klasse\n",
    "model = KNN()\n",
    "# Unterteilung der Samples\n",
    "model.split_sample(pd.DataFrame(wind[\"Ws_avg\"]),pd.DataFrame(wind[\"S_avg\"]),shuffle=shuffle,sections =sections)\n",
    "#Auswahl der Skalierungsmethode\n",
    "model.scaler(\"MinMax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97680c",
   "metadata": {},
   "source": [
    "## Erstellung eines KNN zur Prognose der Einspeisung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4487b",
   "metadata": {},
   "source": [
    "**Definition Features und Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd55a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.numFeatures = 1\n",
    "model.numResponses = 1;\n",
    "model.x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92dcfe",
   "metadata": {},
   "source": [
    "### Hyperparameter definieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204dda9",
   "metadata": {},
   "source": [
    "***HyperParameters (hp)***\n",
    "\n",
    "Die Suche der Hyperparamters muss mit der Tuner API eingenständig definiert werden.<br>\n",
    "\n",
    "Hierzu stehen 4 Variationsmöglichkeiten zur Verfügung:\n",
    "\n",
    "*   `Boolean` —  Choice between True and False.<br>\n",
    "     ***hp.Boolean***(name, default=False,...)    \n",
    "\n",
    "*   `Choice` —  Choice of one value among a predefined set of possible values.<br>\n",
    "     **hp.Choice**(\n",
    "    name, values, ordered=None, default=None,...)\n",
    "\n",
    "*   `Float` —  Floating point value hyperparameter.<br>\n",
    "     ***hp.Float***(name,min_value,max_value,step=None,sampling=\"linear\",default=None,...)\n",
    "*   `Int` —  Integer point value hyperparameter.<br>\n",
    "    ***hp.Int***('units', min_value=32, max_value=128, step=32,default=64)\n",
    "*   `conditional_scope` —  Opens a scope to create conditional HyperParameters.<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0528d8",
   "metadata": {},
   "source": [
    "Die Ausprägungen der Parametervariation wird festgelegt.\n",
    "hp.HParam ist eine Klasse, um die Hyperparameter zu definieren und zu loggen. Die Klasse wird von tensorboard zur Verfügung gestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_units = hp.HParam(name=\"units\",domain = hp.IntInterval(min_value=32, max_value=212))     # Anzahl der Neuronen\n",
    "HP_layers = hp.HParam(name=\"layers\",domain = hp.IntInterval(min_value=0, max_value=2))      # Anzahl der hidden Layer \n",
    "HP_activation = hp.HParam(name=\"activation\",domain=  hp.Discrete([\"relu\", \"tanh\"]))         # Aktivierungsmethode\n",
    "HP_lr = hp.HParam(name = \"lr\", domain= hp.RealInterval(min_value=1e-4, max_value=1e-2))     # Lernrate\n",
    "HP_dropout = hp.HParam('dropout', hp.RealInterval(0.1,0.6))                            # Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c141f",
   "metadata": {},
   "source": [
    "### Modellaufbau mit Keras-functional API Schreibweise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69374d",
   "metadata": {},
   "source": [
    "Beim Aufruf von `single_run` wird das neuronale Netz mit den im aktuellem Lauf gültigen Hyperparameter-Set angelegt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3136d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modellaufbau mit gewählter Hyperparameterausstattung\n",
    "\n",
    "def single_run(hparams):\n",
    "     \n",
    "    # Define model layers.\n",
    "    input_layer = Input(shape=(model.numFeatures,))\n",
    "    \n",
    "    X= Dense(hparams[HP_units],hparams[HP_activation],name='dense1')(input_layer)\n",
    "    if layers >1:\n",
    "        X = [Dense(hparams[HP_units],hparams[HP_activation],\\\n",
    "                             name='dense'+str(i+2))(X) for i in range(layers-1)]\n",
    "  \n",
    "        X = Dropout(hparams[HP_dropout])(X)\n",
    "    \n",
    "    # Output\n",
    "    y_output= Dense(units='1', name='output')(X)  \n",
    "    \n",
    "    # Verbindung von Input und Output-Schicht   \n",
    "    KNN = Model(inputs=input_layer,outputs=y_output)\n",
    "\n",
    "    KNN.compile(optimizer=keras.optimizers.Adam(hparams[HP_lr]),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=keras.losses.MeanAbsoluteError())\n",
    "    \n",
    "    return KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253b852",
   "metadata": {},
   "source": [
    "`run` ist eine Hilfsfunktion mit der ein neuer Lauf mit folgenden Ablauf erstellt wird:\n",
    "1. Erstellung des neuronalen Netz mit übergebenen Hyperparametern `hparams`\n",
    "2. Festlegen des Speicherorts für neue Logdatei\n",
    "3. Durchführen des Trainings und speichern der Ergebnisse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281863f",
   "metadata": {
    "id": "WAQThq539CEJ"
   },
   "outputs": [],
   "source": [
    "def run(run_dir,hparams):\n",
    "    KNN = single_run(hparams)\n",
    "    early = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    KNN.fit(x=model.x_norm[0], \n",
    "          y=model.y_norm[0], \n",
    "          epochs=20,\n",
    "          batch_size= 256, \n",
    "          validation_data=(model.x_norm[1], model.y_norm[1]), \n",
    "          callbacks=[\n",
    "              early,\n",
    "              tf.keras.callbacks.TensorBoard(run_dir),  # log metrics\n",
    "              hp.KerasCallback(run_dir, hparams),       # log hparams\n",
    "                    ],\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76307c1a",
   "metadata": {},
   "source": [
    "### Aufruf des Schleifenumlaufs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09291b2",
   "metadata": {},
   "source": [
    "1. Permutation aller Hyperparameter\n",
    "2. Anstoss der Netzerstellung und des Trainings\n",
    "3. Übermittlung von Informationen zum Stand des Umlaufs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6de797",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for units in (HP_units.domain.min_value, HP_units.domain.max_value):\n",
    "    for layers in (HP_layers.domain.min_value, HP_layers.domain.max_value):\n",
    "        for activation in HP_activation.domain.values:\n",
    "            for lr in (HP_lr.domain.min_value, HP_lr.domain.max_value):\n",
    "                for dropout in np.arange(HP_dropout.domain.min_value, HP_dropout.domain.max_value,.2):\n",
    "                    hparams = {\n",
    "                                HP_units: units,\n",
    "                                HP_layers: layers,\n",
    "                                HP_activation: activation,\n",
    "                                HP_lr:lr,\n",
    "                                HP_dropout:dropout\n",
    "                              }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    print('--- Starting trial: %s' % run_name)\n",
    "                    print({h.name: hparams[h] for h in hparams})\n",
    "                    # start des nächsten Umlaufs mit veränderten Parametern\n",
    "                    run('logs/hparam_tuning/' + run_name, hparams)\n",
    "                    session_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a3ab5",
   "metadata": {},
   "source": [
    "Start TensorBoard through the command line or within a notebook experience. The two interfaces are generally the same. In notebooks, use the `%tensorboard` line magic. On the command line, run the same command without \"%\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cee232",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --port 6031 --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0eeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/runall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbbf9a",
   "metadata": {
    "id": "Gi4PaRm39of2",
    "tags": []
   },
   "source": [
    "A brief overview of the visualizations created in this example and the dashboards (tabs in top navigation bar) where they can be found:\n",
    "\n",
    "* **Scalars** show how the loss and metrics change with every epoch. You can use them to also track training speed, learning rate, and other scalar values. Scalars can be found in the **Time Series** or **Scalars** dashboards.\n",
    "* **Graphs** help you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly. Graphs can be found in the **Graphs** dashboard.\n",
    "* **Histograms** and **Distributions** show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way. Histograms can be found in the **Time Series** or **Histograms** dashboards. Distributions can be found in the **Distributions** dashboard.\n",
    "\n",
    "Additional TensorBoard dashboards are automatically enabled when you log other types of data. For example, the Keras TensorBoard callback lets you log images and embeddings as well. You can see what other dashboards are available in TensorBoard by clicking on the \"inactive\" dropdown towards the top right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe56c999",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The left pane of the dashboard provides filtering capabilities that are active across all the views in the HParams dashboard:\n",
    "\n",
    "    Filter which hyperparameters/metrics are shown in the dashboard\n",
    "    Filter which hyperparameter/metrics values are shown in the dashboard\n",
    "    Filter on run status (running, success, ...)\n",
    "    Sort by hyperparameter/metric in the table view\n",
    "    Number of session groups to show (useful for performance when there are many experiments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66648fd1",
   "metadata": {},
   "source": [
    "he HParams dashboard has three different views, with various useful information:\n",
    "\n",
    "    The Table View lists the runs, their hyperparameters, and their metrics.\n",
    "    The Parallel Coordinates View shows each run as a line going through an axis for each hyperparemeter and metric. Click and drag the mouse on any axis to mark a region which will highlight only the runs that pass through it. This can be useful for identifying which groups of hyperparameters are most important. The axes themselves can be re-ordered by dragging them.\n",
    "    The Scatter Plot View shows plots comparing each hyperparameter/metric with each metric. This can help identify correlations. Click and drag to select a region in a specific plot and highlight those sessions across the other plots.\n",
    "\n",
    "A table row, a parallel coordinates line, and a scatter plot market can be clicked to see a plot of the metrics as a function of training steps for that session (although in this tutorial only one step is used for each run)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

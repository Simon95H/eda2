{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcfa095",
   "metadata": {},
   "source": [
    "# Modellierung Windeinspeisung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee54efc",
   "metadata": {},
   "source": [
    "**Lernziele**\n",
    "- Hyperparameteroptimierung mit keras-tuner\n",
    "\n",
    "**!!!!Hinweis!!!!\n",
    "Sie müssen bei den Paketen den Pfad zu den \"internalfunctions\" richtig setzen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b997b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pakete und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559b358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datenorganisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# Ploterstellung\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "# Datenvorbereitung\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Standardeinstellungen\n",
    "plt.rcParams['axes.xmargin'] = 0\n",
    "pd.set_option('display.precision',3)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Input, LSTM, Dense, Bidirectional, Dropout)\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint)\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#tf.config.list_physical_devices('GPU')\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorboard\n",
    "tensorboard.__version__\n",
    "\n",
    "#sonst  Module \n",
    "import copy\n",
    "import sys\n",
    "from math import ceil\n",
    "\n",
    "# Eingene Module \n",
    "# temporäre Einbinden des neuen Pfades mit zu ladenden Dateien\n",
    "sys.path.append(\"C:\\\\Users\\\\rs3753e\\\\sciebo\\\\Vorlesungen\\\\SoSe_Energiedatenanalyse Datamining\\\\internalfunctions\\\\\")\n",
    "from KNN import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8524a82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WICHTIG: alte Verzeichnis-Daten werden gelöscht\n",
    "\n",
    "# Laden des vorbereiteten WinddatenFrame\n",
    "wind=pd.read_hdf('../daten/windeinspeisung_bereinigt','Obj1')\n",
    "wind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31153d72",
   "metadata": {},
   "source": [
    "## Datenorganisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cda96a",
   "metadata": {},
   "source": [
    "Erstellung eines KNN-Objektes mit normierten/Standardisierten Trainings/Validierungs- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6060f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vorgaben zur Datentrennung\n",
    "sections=(.6,.25,.15)\n",
    "shuffle=False\n",
    "\n",
    "# Vorbereitete Klasse\n",
    "model = KNN()\n",
    "# Unterteilung der Samples\n",
    "model.split_sample(pd.DataFrame(wind[\"Ws_avg\"]),pd.DataFrame(wind[\"S_avg\"]),shuffle=shuffle,sections =sections)\n",
    "#Auswahl der Skalierungsmethode\n",
    "model.scaler(\"MinMax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af04bd",
   "metadata": {},
   "source": [
    "## Erstellung eines KNN zur Prognose der Einspeisung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a5b42",
   "metadata": {},
   "source": [
    "**Definition Features und Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dbd30ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.numFeatures = 1\n",
    "model.numResponses = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a7ad28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121071, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ae6fa",
   "metadata": {},
   "source": [
    "### Modellaufbau mit Keras-functional API Schreibweise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9dce9",
   "metadata": {},
   "source": [
    "***HyperParameters (hp)***\n",
    "\n",
    "Die Suche der Hyperparamters muss mit der Tuner API eingenständig definiert werden.<br>\n",
    "\n",
    "Hierzu stehen 4 Variationsmöglichkeiten bei den (Hyper)-Parametern zur Verfügung:\n",
    "\n",
    "*   `Boolean` —  Choice between True and False.<br>\n",
    "     hp.Boolean(name, default=False,...)    \n",
    "\n",
    "*   `Choice` —  Choice of one value among a predefined set of possible values.<br>\n",
    "     hp.Choice(\n",
    "    name, values, ordered=None, default=None,...)\n",
    "\n",
    "*   `Int` —  Integer point value hyperparameter.<br>\n",
    "    hp.Int('units', min_value=32, max_value=128, step=32,default=64)\n",
    "\n",
    "*   `Float` —  Floating point value hyperparameter.<br>\n",
    "     hp.Float(name,min_value,max_value,step=None,sampling=\"linear\",default=None,...)\n",
    "\n",
    "\n",
    "*   `conditional_scope` —  Opens a scope to create conditional HyperParameters.<br> \n",
    "\n",
    "Im  Beispiel werden folgende Parameter variiert (Variationsmehtode in Klammern):\n",
    "- units (Int)\n",
    "- Anzahl der hidden-Layer (Int)\n",
    "- Learning rate (Choice)\n",
    "- Layerdropout (Boolean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6b4518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode zur Auswahl der zu variierenden  Hyperparameter\n",
    "def build_model(hp):                                                                #     hp ist Objekt von Keras Tuner zur Hyperparameteroptimierung\n",
    "    \n",
    "    # Erstellung der relevanten Parametern und deren Variationen\n",
    "    \n",
    "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)                   # Anzahl Neuronen\n",
    "    layers = hp.Int(\"layers\", min_value=1, max_value=2, step=1)                     # Anzahl der Layer\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])                          # Form der Aktivierung\n",
    "    dropout = hp.Boolean(\"dropout\")                                                 # dropout ja / nein\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")             # Lernrate\n",
    "    \n",
    "    \n",
    "    # Aufruf der Modellerstellung auf Basis der gewählten Hyperparameter \n",
    "    KNN = single_call(\n",
    "        units=units,layers=layers, activation=activation, dropout=dropout, lr=lr\n",
    "    )\n",
    "    # Rückgabe des Netzes\n",
    "    return KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ea783",
   "metadata": {},
   "source": [
    "***dynamischer Aufbau der Netztopologie***\n",
    "\n",
    "Für die jeweiligen Parameterkonstellationen, welche bei der (Hyper)-Parametersuche in Frage kommen, wird ein eigenständiger Methodenaufruf definiert mit Übergabeobjekt `hp`. \n",
    "\n",
    "Für die Erstellung des neuronalen Netzes wird die funktionale API verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bbf8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellaufbau mit gewählter Hyperparameterausstattung\n",
    "def single_call(units, layers,activation, dropout, lr):\n",
    "     \n",
    "    # Define model layers.\n",
    "    input_layer = Input(shape=(model.numFeatures,))\n",
    "    \n",
    "    X= Dense(units=units,activation=activation,name='dense1')(input_layer)\n",
    "    if layers >1:\n",
    "        X = [Dense(units=units,activation=activation,\\\n",
    "                             name='dense'+str(i+2))(X) for i in range(layers-1)]\n",
    "    if dropout==True:\n",
    "        X = Dropout(rate=0.25)(X)\n",
    "    \n",
    "    # Output\n",
    "    y_output= Dense(units='1', name='output')(X)  \n",
    "    \n",
    "    # Verbindung von Input und Output-Schicht   \n",
    "    KNN = Model(inputs=input_layer,outputs=y_output)\n",
    "\n",
    "    KNN.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=keras.losses.MeanAbsoluteError())\n",
    "    \n",
    "    return KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac573e1",
   "metadata": {},
   "source": [
    "**Initialisierung des Tuners und Durchführung des hypertunings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26589377",
   "metadata": {},
   "source": [
    "The base Tuner class is the class that manages the hyperparameter search process, including model creation, training, and evaluation. For each trial, a Tuner receives new hyperparameter values from an Oracle instance. After calling model.fit(...), it sends the evaluation results back to the Oracle instance and it retrieves the next set of hyperparameters to try.\n",
    "\n",
    "Es stehen in Keras 3 verschiedene Möglichkeiten der Hyperparameteroptimierung zur Verfügung. die Verfahren unterscheiden sich im Wesentlichen durch die Form des Suchalgorithmus (siehe Vorlesungsunterlagen)\n",
    "\n",
    "- RandomSearch            \n",
    "- BayesianOptimization\n",
    "- Hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9736f",
   "metadata": {},
   "source": [
    "**Argumente der Initialisierung**\n",
    "\n",
    "Bei Instanzierung einer definierten Suchalgorithmus-Klasse können entsprechende Argumente übergeben werden \n",
    "```python\n",
    "keras_tuner.BayesianOptimization(\n",
    "    hypermodel=None,\n",
    "    objective=None,\n",
    "    max_trials=10,\n",
    "    num_initial_points=None,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    max_retries_per_trial=0,\n",
    "    max_consecutive_failed_trials=3,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "``` \n",
    "Wir übergeben hierbei die Argumente `hypermodel` und `input_shape` zu übergeben.\n",
    "*   `hypermodel` —  übergibt den Modellaufbau (in unseren Fall die Methode build_model)\n",
    "\n",
    "*   `objective` — verwendete Zielfunktion in der Suche. Wichtig ist es hierbei eine Verlustfunktion auf Basis der Validierungsdaten zu verwenden\n",
    "\n",
    "*   `max_trials:` — Anzahl der Versuche (model configurations) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b95e31",
   "metadata": {},
   "source": [
    "**Umsetzung der Initialisierung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b84ccba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "kwarg = {'project_name':'basian_search','overwrite': True}\n",
    "\n",
    "tuner = kt.BayesianOptimization(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=40,\n",
    "                     **kwarg)\n",
    "\n",
    "# Zusammenfassung\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8d010",
   "metadata": {},
   "source": [
    "**bereitgestellte Methoden des tuner-Objektes** \n",
    "\n",
    "*    `search`(*fit_args, **fit_kwargs) - Performs a search for best hyperparameter configuations.\n",
    "\n",
    "*    `results_summary` - Print search space summary.\n",
    "\n",
    "*    `search_space_summary`(*fit_args, **fit_kwargs) - Performs a search for best hyperparameter configuations.\n",
    "\n",
    "*    `get_best_hyperparameters` - Returns the best hyperparameters, as determined by the objective.<br> **Arguments:**  num_trials: Optional number of HyperParameters objects to return. <br>**Returns:** List of HyperParameter objects sorted from the best to the worst.\n",
    "\n",
    "*    `get_best_models` - Returns the best model(s), as determined by the tuner's objective.\n",
    "\n",
    "*    `results_summary` - The method prints a summary of the search results including the hyperparameter values and evaluation results for each trial.\n",
    "**Arguments:**  num_trials: Optional number of trials to display. Defaults to 10.\n",
    "\n",
    "*    `load_model` - Loads a Model from a given trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e41c8a",
   "metadata": {},
   "source": [
    "**Durchführung der Parametersuche**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4afeccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 Complete [00h 00m 09s]\n",
      "val_loss: 0.005034321919083595\n",
      "\n",
      "Best val_loss So Far: 0.0048936656676232815\n",
      "Total elapsed time: 00h 06m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "stop_early = EarlyStopping(monitor='val_loss', patience=10)\n",
    "tuner.search(model.x_norm[0],model.y_norm[0],batch_size = 512,epochs =10,validation_data=(model.x_norm[1],model.y_norm[1]), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91733667",
   "metadata": {},
   "source": [
    "**Sichtung der Ergebnisse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8de697aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner.results_summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f81d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# Alternative A: Get the top model.\n",
    "best_models = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "257270e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative B: Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664c064",
   "metadata": {},
   "source": [
    "**Re-Trainieren des besten neuronalen Netzes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d07b71a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 384)               768       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 385       \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0076 - mean_absolute_error: 0.0457 - val_loss: 0.0057 - val_mean_absolute_error: 0.0296\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_absolute_error: 0.0229 - val_loss: 0.0054 - val_mean_absolute_error: 0.0286\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_absolute_error: 0.0231 - val_loss: 0.0054 - val_mean_absolute_error: 0.0275\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_absolute_error: 0.0221 - val_loss: 0.0052 - val_mean_absolute_error: 0.0266\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_absolute_error: 0.0208 - val_loss: 0.0050 - val_mean_absolute_error: 0.0253\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0199 - val_loss: 0.0053 - val_mean_absolute_error: 0.0271\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0202 - val_loss: 0.0051 - val_mean_absolute_error: 0.0252\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0198 - val_loss: 0.0049 - val_mean_absolute_error: 0.0266\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0195 - val_loss: 0.0050 - val_mean_absolute_error: 0.0250\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0193 - val_loss: 0.0051 - val_mean_absolute_error: 0.0256\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0195 - val_loss: 0.0050 - val_mean_absolute_error: 0.0252\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0198 - val_loss: 0.0051 - val_mean_absolute_error: 0.0258\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0199 - val_loss: 0.0049 - val_mean_absolute_error: 0.0273\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0196 - val_loss: 0.0049 - val_mean_absolute_error: 0.0269\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0197 - val_loss: 0.0052 - val_mean_absolute_error: 0.0269\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 0s 4ms/step - loss: 0.0021 - mean_absolute_error: 0.0192 - val_loss: 0.0053 - val_mean_absolute_error: 0.0273\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0194 - val_loss: 0.0049 - val_mean_absolute_error: 0.0272\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_absolute_error: 0.0194 - val_loss: 0.0052 - val_mean_absolute_error: 0.0254\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model_best = tuner.hypermodel.build(best_hps)\n",
    "model_best.summary()\n",
    "history = model_best.fit(model.x_norm[0],model.y_norm[0], epochs=100, batch_size=1000,validation_data=(model.x_norm[1],model.y_norm[1]),callbacks=[stop_early])\n",
    "\n",
    "val_loss_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_loss_per_epoch.index(max(val_loss_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85a027",
   "metadata": {},
   "source": [
    "**Plot Verlauf der Verlustfunktion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70e3c321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(nrows=1,ncols=1,**{'figsize': (18, 7)})\n",
    "# ersten 5 werden ausgeblendet\n",
    "lin1 = ax.plot(history.history['val_loss'][5:],label='val_loss')\n",
    "lin2 = ax.plot(history.history['loss'][5:],label='loss')\n",
    "ax.set(xlabel='Epoche',ylabel='loss')\n",
    "ax.legend();ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb4e689",
   "metadata": {},
   "source": [
    "**Prognose von Training, Validierungs- und Testdaten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7994b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prognose\n",
    "ypred_norm =list();[ypred_norm.append(model_best.predict(model.x_norm[i])) for i in range(3)];\n",
    "# Inverse Scalierung\n",
    "ypred =list();[ypred.append(model.scalerY.inverse_transform(ypred_norm[i])) for i in range(3)];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f314a8a",
   "metadata": {},
   "source": [
    "**Verlauf Plot Orginal vs. Prognose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12344311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab =[\"Training\", \"Validierung\",\"Test\"]\n",
    "fig, ax =plt.subplots(nrows=1,ncols=3,**{'figsize': (18, 8)})\n",
    "for i in range(3):\n",
    "  \n",
    "    # 50% Quantil'\n",
    "    ax[i].plot(model.x[i].index[0:1000],ypred[i][0:1000],label='pred',color = 'r',linewidth =.5)\n",
    "\n",
    "    # realer Wert\n",
    "    ax[i].plot(model.x[i].index[0:1000],model.y[i][0:1000],label='real',color = 'k',linewidth =.5)\n",
    "    ax[i].set(ylabel=\"Leistung [MW]\",xlabel=\"Zeit\",title=lab[i],ylim=(0,2200));\n",
    "    ax[i].legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
